resource_registry:
  OS::TripleO::Services::CephMgr: ../../deployment/cephadm/ceph-mgr.yaml
  OS::TripleO::Services::CephMon: ../../deployment/cephadm/ceph-mon.yaml
  OS::TripleO::Services::CephOSD: ../../deployment/cephadm/ceph-osd.yaml
  OS::TripleO::Services::CephGrafana: ../../deployment/cephadm/ceph-grafana.yaml
  OS::TripleO::Services::CephClient: ../../deployment/cephadm/ceph-client.yaml
  OS::TripleO::Services::CeilometerAgentCentral: ../../deployment/ceilometer/ceilometer-agent-central-container-puppet.yaml
  OS::TripleO::Services::CeilometerAgentNotification: ../../deployment/ceilometer/ceilometer-agent-notification-container-puppet.yaml
  OS::TripleO::Services::CeilometerAgentIpmi: ../../deployment/ceilometer/ceilometer-agent-ipmi-container-puppet.yaml
  OS::TripleO::Services::ComputeCeilometerAgent: ../../deployment/ceilometer/ceilometer-agent-compute-container-puppet.yaml
  OS::TripleO::Services::Collectd: ../../deployment/metrics/collectd-container-puppet.yaml
  OS::TripleO::Services::MetricsQdr: ../../deployment/metrics/qdr-container-puppet.yaml
  OS::TripleO::Services::OsloMessagingRpc: ../../deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml
  OS::TripleO::Services::OsloMessagingNotify: ../../deployment/rabbitmq/rabbitmq-messaging-notify-shared-puppet.yaml
  OS::TripleO::Services::HAproxy: ../../deployment/haproxy/haproxy-pacemaker-puppet.yaml
  OS::TripleO::Services::Pacemaker: ../../deployment/pacemaker/pacemaker-baremetal-puppet.yaml
  OS::TripleO::Services::PacemakerRemote: ../../deployment/pacemaker/pacemaker-remote-baremetal-puppet.yaml
  OS::TripleO::Services::Clustercheck: ../../deployment/pacemaker/clustercheck-container-puppet.yaml
  OS::TripleO::Services::Redis: ../../deployment/database/redis-pacemaker-puppet.yaml
  OS::TripleO::Services::MySQL: ../../deployment/database/mysql-pacemaker-puppet.yaml
  OS::TripleO::Services::CinderBackup: ../../deployment/cinder/cinder-backup-pacemaker-puppet.yaml
  OS::TripleO::Services::CinderVolume: ../../deployment/cinder/cinder-volume-pacemaker-puppet.yaml
  OS::TripleO::Services::HeatApi: ../../deployment/heat/heat-api-container-puppet.yaml
  OS::TripleO::Services::HeatApiCfn: ../../deployment/heat/heat-api-cfn-container-puppet.yaml
  OS::TripleO::Services::HeatEngine: ../../deployment/heat/heat-engine-container-puppet.yaml

parameter_defaults:
  ControllerNetworkConfigTemplate: 'templates/ci/multinode.j2'
  ComputeNetworkConfigTemplate: 'templates/ci/multinode.j2'
  ControllerServices:
    - OS::TripleO::Services::CACerts
    - OS::TripleO::Services::Clustercheck
    - OS::TripleO::Services::ContainerImagePrepare
    - OS::TripleO::Services::Podman
    - OS::TripleO::Services::Kernel
    - OS::TripleO::Services::Keystone
    - OS::TripleO::Services::LoginDefs
    - OS::TripleO::Services::GlanceApi
    - OS::TripleO::Services::GlanceApiInternal
    - OS::TripleO::Services::HeatApi
    - OS::TripleO::Services::HeatApiCfn
    - OS::TripleO::Services::HeatEngine
    - OS::TripleO::Services::MySQL
    - OS::TripleO::Services::MySQLClient
    - OS::TripleO::Services::NeutronApi
    - OS::TripleO::Services::NeutronCorePlugin
    - OS::TripleO::Services::OVNDBs
    - OS::TripleO::Services::OVNController
    - OS::TripleO::Services::OVNMetadataAgent
    - OS::TripleO::Services::OsloMessagingRpc
    - OS::TripleO::Services::OsloMessagingNotify
    - OS::TripleO::Services::HAproxy
    - OS::TripleO::Services::Memcached
    - OS::TripleO::Services::Pacemaker
    - OS::TripleO::Services::NovaConductor
    - OS::TripleO::Services::NovaApi
    - OS::TripleO::Services::PlacementApi
    - OS::TripleO::Services::NovaMetadata
    - OS::TripleO::Services::NovaScheduler
    - OS::TripleO::Services::Snmp
    - OS::TripleO::Services::Sshd
    - OS::TripleO::Services::Securetty
    - OS::TripleO::Services::Timesync
    - OS::TripleO::Services::Timezone
    - OS::TripleO::Services::NovaCompute
    - OS::TripleO::Services::NovaLibvirt
    - OS::TripleO::Services::NovaMigrationTarget
    - OS::TripleO::Services::Redis
    - OS::TripleO::Services::AodhApi
    - OS::TripleO::Services::AodhEvaluator
    - OS::TripleO::Services::AodhNotifier
    - OS::TripleO::Services::AodhListener
    - OS::TripleO::Services::CeilometerAgentCentral
    - OS::TripleO::Services::CeilometerAgentIpmi
    - OS::TripleO::Services::CeilometerAgentNotification
    - OS::TripleO::Services::ComputeCeilometerAgent
    - OS::TripleO::Services::GnocchiApi
    - OS::TripleO::Services::GnocchiMetricd
    - OS::TripleO::Services::GnocchiStatsd
    - OS::TripleO::Services::CephMgr
    - OS::TripleO::Services::CephMon
    - OS::TripleO::Services::CephOSD
    - OS::TripleO::Services::CephClient
    - OS::TripleO::Services::CinderApi
    - OS::TripleO::Services::CinderBackup
    - OS::TripleO::Services::CinderScheduler
    - OS::TripleO::Services::CinderVolume
    - OS::TripleO::Services::Collectd
    - OS::TripleO::Services::MetricsQdr
    - OS::TripleO::Services::TripleoPackages
    - OS::TripleO::Services::TripleoFirewall
    - OS::TripleO::Services::Iscsid
    - OS::TripleO::Services::Multipathd

  ControllerExtraConfig:
    nova::compute::libvirt::services::libvirt_virt_type: qemu
    nova::compute::libvirt::virt_type: qemu
    # NOTE(sileht): To decrease the time test_telemetry_integration takes We
    # configure Ceilometer to poll more, We configure the
    # 'ceilometer-high-rate' Gnocchi archive policy to keep 1 point every 60s.
    # The test will take 2 minutes instead of 10 minutes. Note that tempest
    # telemetry.alarm_granularity must in sync with the archive policy, 60s
    # too.
    ceilometer::agent::polling::polling_interval: 15
    # NOTE(mmagr): uncomment when QDR mesh will actually work (followup on review.opendev.org/702754)
    #tripleo::profile::base::metrics::qdr::router_mode: interior
  NotificationDriver: 'messagingv2'
  ManagePolling: true
  ManagePipeline: true
  CeilometerEnableGnocchi: true
  PipelinePublishers:
    - gnocchi://?archive_policy=ceilometer-high-rate
  EventPipelinePublishers:
    - gnocchi://?archive_policy=ceilometer-high-rate
  CeilometerQdrPublishEvents: true
  ManageEventPipeline: true
  Debug: true
  DockerPuppetDebug: True
  CephPools:
    - name: altrbd
      rule_name: replicated_rule
  #NOTE: These ID's and keys should be regenerated for
  # a production deployment. What is here is suitable for
  # developer and CI testing only.
  CephClusterFSID: '4b5c8c0a-ff60-454b-a1b4-9747aa737d19'
  CephClientKey: 'AQC+vYNXgDAgAhAAc8UoYt+OTz5uhV7ItLdwUw=='
  CephEnableDashboard: true
  NovaEnableRbdBackend: true
  CinderEnableRbdBackend: true
  CinderRbdExtraPools: altrbd
  CinderBackupBackend: ceph
  GlanceBackend: rbd
  GnocchiBackend: rbd
  CinderEnableIscsiBackend: false
  BannerText: |
    ******************************************************************
    * This system is for the use of authorized users only. Usage of  *
    * this system may be monitored and recorded by system personnel. *
    * Anyone using this system expressly consents to such monitoring *
    * and is advised that if such monitoring reveals possible        *
    * evidence of criminal activity, system personnel may provide    *
    * the evidence from such monitoring to law enforcement officials.*
    ******************************************************************
  CollectdConnectionType: amqp1
  CollectdExtraPlugins:
    - rrdtool
  CollectdEnableSensubility: true
  CollectdEnableLibpodstats: true
  LoggingServers:
    - host: 127.0.0.1
      port: 24224
  TtyValues:
    - console
    - tty1
    - tty2
    - tty3
    - tty4
    - tty5
    - tty6
  # Remove ContainerCli once this scenario is tested on CentOS8
  ContainerCli: podman
  CephConfigPath: "/etc/ceph"
  CephClientConfigVars: "{{ playbook_dir }}/cephadm/ceph_client.yml"
  CephSpecFqdn: true
  CephOsdSpec:
    data_devices:
      paths:
        - /dev/ceph_vg/ceph_lv_data
