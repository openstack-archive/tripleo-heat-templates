heat_template_version: rocky

description: >
  Ceph NFS Ganeshaservice.

parameters:
  ServiceData:
    default: {}
    description: Dictionary packing service data
    type: json
  ServiceNetMap:
    default: {}
    description: Mapping of service_name -> network name. Typically set
                 via parameter_defaults in the resource registry.  This
                 mapping overrides those in ServiceNetMapDefaults.
    type: json
  DefaultPasswords:
    default: {}
    type: json
  RoleName:
    default: ''
    description: Role name on which the service is applied
    type: string
  RoleParameters:
    default: {}
    description: Parameters specific to the role
    type: json
  EndpointMap:
    default: {}
    description: Mapping of service endpoint -> protocol. Typically set
                 via parameter_defaults in the resource registry.
    type: json
  ManilaCephFSCephFSAuthId:
    type: string
    default: 'manila'
  ManilaCephFSNFSIdmapConf:
    type: string
    default: '/etc/ganesha/idmap.conf'
  ManilaCephFSNFSIdmapOverrides:
    type: json
    description: Extra config settings to dump into idmap.conf
    default: {}

resources:
  CephBase:
    type: ./ceph-base.yaml
    properties:
      ServiceData: {get_param: ServiceData}
      ServiceNetMap: {get_param: ServiceNetMap}
      DefaultPasswords: {get_param: DefaultPasswords}
      EndpointMap: {get_param: EndpointMap}
      RoleName: {get_param: RoleName}
      RoleParameters: {get_param: RoleParameters}

  CephNfsAnsibleVars:
    type: OS::Heat::Value
    properties:
      type: json
      value:
        vars:
          ceph_nfs_bind_addr: {get_param: [EndpointMap, GaneshaInternal, host_nobrackets]}
          ceph_nfs_enable_service: false
          ceph_nfs_use_pacemaker: true
          ceph_nfs_dynamic_exports: true
          ceph_nfs_service_suffix: pacemaker
          nfs_obj_gw: false
          ceph_nfs_rados_backend: true
          ceph_nfs_disable_caching: true
          ceph_nfs_ceph_user: {get_param: ManilaCephFSCephFSAuthId}
          ceph_nfs_idmap_conf: {get_param: ManilaCephFSNFSIdmapConf}
          idmap_conf_overrides: {get_param: ManilaCephFSNFSIdmapOverrides}

outputs:
  role_data:
    description: Role data for the Ceph NFS Ganesha service.
    value:
      service_name: ceph_nfs
      upgrade_tasks:
        - name: Create hiera data to upgrade ceph_nfs in a stepwise manner.
          when:
            - step|int == 1
            - cluster_recreate|bool
          block:
            - name: set ceph_nfs upgrade node facts in a single-node environment
              set_fact:
                ceph_nfs_short_node_names_upgraded: "{{ ceph_nfs_short_node_names }}"
                cacheable: no
              when: groups['ceph_nfs'] | length <= 1
            - name: set ceph_nfs upgrade node facts from the limit option
              set_fact:
                ceph_nfs_short_node_names_upgraded: "{{ ceph_nfs_short_node_names_upgraded|default([]) + [item.split('.')[0]] }}"
                cacheable: no
              when:
                - groups['ceph_nfs'] | length > 1
                - item.split('.')[0] in ansible_limit.split(':')
              loop: "{{ ceph_nfs_short_node_names | default([]) }}"
            - fail:
                msg: >
                  You can't upgrade ceph_nfs without staged
                  upgrade. You need to use the limit option in order
                  to do so.
              when: >-
                ceph_nfs_short_node_names_upgraded is not defined or
                ceph_nfs_short_node_names_upgraded | length == 0
            - debug:
                msg: "Prepare ceph_nfs upgrade for {{ ceph_nfs_short_node_names_upgraded }}"
            - name: add the ceph_nfs short name to hiera data for the upgrade.
              include_role:
                name: tripleo-upgrade-hiera
                tasks_from: set.yml
              vars:
                tripleo_upgrade_key: ceph_nfs_short_node_names_override
                tripleo_upgrade_value: "{{ceph_nfs_short_node_names_upgraded}}"
            - name: remove the extra hiera data needed for the upgrade.
              include_role:
                name: tripleo-upgrade-hiera
                tasks_from: remove.yml
              vars:
                tripleo_upgrade_key: ceph_nfs_short_node_names_override
              when: ceph_nfs_short_node_names_upgraded | length == ceph_nfs_short_node_names | length
      step_config: 'include tripleo::profile::pacemaker::ceph_nfs'
      puppet_config:
        config_image: ''
        config_volume: ''
        step_config: ''
      # step_config seems to be ignored if docker_config is present
      #docker_config: {}
      external_deploy_tasks:
        list_concat:
        - {get_attr: [CephBase, role_data, external_deploy_tasks]}
        - - name: ceph_nfs_external_deploy_init
            when: step|int == 1
            tags:
              - ceph
              - ceph_fstobs
              - ceph_systemd
            block:
              - name: set ceph-ansible group vars nfss
                set_fact:
                  ceph_ansible_group_vars_nfss: {get_attr: [CephNfsAnsibleVars, value, vars]}
              - name: generate ceph-ansible group vars nfss
                become: true
                copy:
                  mode: '0640'
                  dest: "{{playbook_dir}}/ceph-ansible/group_vars/nfss.yml"
                  content: "{{ceph_ansible_group_vars_nfss|to_nice_yaml}}"
        - - name: Restart ceph-nfs daemon
            become: true
            when:
              - ceph_ansible_playbooks_default is defined
              - step|int == 3
              - '"/usr/share/ceph-ansible/infrastructure-playbooks/rolling_update.yml" in ceph_ansible_playbooks_default'
            tags:
              - ceph
            block:
              - name: reload systemd daemon
                systemd:
                  daemon_reload: yes
              # (fpantano) ceph-nfs@.service ExecStop doesn't work properly when the unit is ceph4
              # but there's still a ceph3 container running
              - name: look for any ceph3 ceph-nfs leftovers
                command: "{{ container_cli }} ps -q -f 'name=ceph-?(.*)-nfs.*'"
                delegate_to: '{{hostvars[groups[''overcloud''][0]][''ceph_nfs_short_bootstrap_node_name'']}}'
                register: ceph_nfs_id
                run_once: true
              - name: stop ceph3 ceph-nfs containers
                command: "{{ container_cli }} stop {{ ceph_nfs_id.stdout_lines[0] }}"
                delegate_to: '{{hostvars[groups[''overcloud''][0]][''ceph_nfs_short_bootstrap_node_name'']}}'
                when: ceph_nfs_id.stdout | length > 0
                run_once: true
              - name: restart the ceph-nfs daemon
                command: "pcs resource restart ceph-nfs"
                delegate_to: '{{hostvars[groups[''overcloud''][0]][''ceph_nfs_short_bootstrap_node_name'']}}'
                run_once: true
        - - name: Cleanup ceph-nfs daemon
            become: true
            command: "pcs resource cleanup ceph-nfs"
            delegate_to: '{{hostvars[groups[''overcloud''][0]][''ceph_nfs_short_bootstrap_node_name'']}}'
            run_once: true
            when:
              - ceph_ansible_playbooks_default is defined
              - step|int == 5
              - '"/usr/share/ceph-ansible/infrastructure-playbooks/rolling_update.yml" in ceph_ansible_playbooks_default'
            tags:
              - ceph
      external_update_tasks: {get_attr: [CephBase, role_data, external_update_tasks]}
      external_upgrade_tasks: {get_attr: [CephBase, role_data, external_upgrade_tasks]}
      config_settings:
        map_merge:
        - tripleo::ceph_nfs::firewall_rules:
            '120 ceph_nfs':
              dport:
              # We support only NFS 4.1 to start
              - 2049
        - {}
